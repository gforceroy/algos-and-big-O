# Intro to Algorithm Complexity & Big O Notation

## Overview
This lesson covers the basics of Big O notation.

There are two components to this lesson:
1. Lecture
2. In-Class Exercise: [Analyzing Algorithms](Big-O-Exercises.md)

## Learning Objectives
By the end of this lesson, you'll be able to:
- Explain how Big O notation is used to describe algorithms.
- Define constant, linear, quadratic, logarithmic, and factorial Big O runtimes.
- Analyze algorithms to determine their Big O runtime.

## Prerequisites
* None

## Duration
1 hour total:
* 0.3 hour lecture
* 0.4 hour exercise 
* 0.3 hour review

A computer algorithm is a series of steps the machine takes in order to take an input and compute an output. There are several ways to measure its performance. One of the metrics used to compare algorithms is using this notion of algorithm complexity.

## Why big O notation is Important?

But what we want to do with this knowledge is to improve the performance of a software application. This is why it's important to understand which algorithm to use, depending upon the problem at hand.





## Additional Resources
- [The Big O Cheat Sheet](http://bigocheatsheet.com/) is the authority on Big O complexities.
